---
title:          "Mitigating Goal Misgeneralization via Minimax Regret"
date:           2025-05-26 00:01:00 +0800
selected:       true
pub:            "Reinforcement Learning Conference (RLC)"
pub_date:       "2025"
abstract: >-
   Goal misgeneralization can occur when the policy generalizes capably with respect to a 'proxy goal' whose optimal behavior correlates with the intended goal on the training distribution, but not out of distribution. We observe that if some training signal towards the intended reward function exists, it can be amplified by regret-based prioritization. We formally show that approximately optimal policies on maximal-regret levels avoid the harmful effects of goal misgeneralization, which may exist without this prioritization. Empirically, we find that current regret-based Unsupervised Environment Design (UED) methods can mitigate the effects of goal misgeneralizatio.

cover:          /assets/images/covers/gmg.png
authors:
  - Karim Abdel Sadek*
  - Matthew Farrugia-Roberts*
  - Usman Anwar
  - Hannah Erlebach
  - Christian Schroeder de Witt
  - David Krueger
  - Michael Dennis
links:
  Paper: https://www.arxiv.org/pdf/2507.03068
---
